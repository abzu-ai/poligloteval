{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb9153a-12c7-431b-9525-e9fd510d20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XDG_CACHE=/workspace/.cache\n",
      "env: HF_HOME=/workspace/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "%env XDG_CACHE=/workspace/.cache\n",
    "%env HF_HOME=/workspace/.cache/huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43381932-7061-42a9-ade7-27eac3938b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d04eac3-fa9a-4e5a-a7e3-d4bcf04142be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"projecte-aina/catalanqa\")\n",
    "df = dataset['train'].to_pandas()\n",
    "# Parameters\n",
    "seed = 42\n",
    "few_shot_count = 5\n",
    "random.seed(seed)\n",
    "\n",
    "# Filter the DataFrame based on the contexts that appear more than few_shot_count times\n",
    "context_counts = df.groupby('context')['id'].count()\n",
    "filter_min_few_shot = context_counts > few_shot_count\n",
    "filtered_df = df[df['context'].isin(context_counts[filter_min_few_shot].index)]\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tracker for samples\n",
    "context_samples = {}\n",
    "\n",
    "# Apply track_samples to dataset\n",
    "for example in dataset:\n",
    "    context = example['context']\n",
    "    if context not in context_samples:\n",
    "        context_samples[context] = []\n",
    "    if len(context_samples[context]) < few_shot_count + 1:\n",
    "        context_samples[context].append(example)\n",
    "\n",
    "# Now, process the tracked samples\n",
    "def create_prompt_and_answer(context):\n",
    "    samples = context_samples[context]\n",
    "    prompt = f\"{samples[0]['context']}\" + \"\\n----\\n\"\n",
    "    prompt += \"\\n----\\n\".join(\n",
    "        f\"Pregunta: {sample['question']}\\nResposta: {sample['answers'][0]['text']}\"\n",
    "        for sample in samples[:-1]\n",
    "    )\n",
    "    last = samples[-1]\n",
    "    prompt += \"\\n----\\n\" + f\"Pregunta: {last['question']}\\nResposta:\"\n",
    "    return {\n",
    "        'context': context,\n",
    "        'prompt': prompt,\n",
    "        'answer': last['answers'][0]['text']\n",
    "    }\n",
    "\n",
    "# Create a new dataset from the processed samples\n",
    "processed_dataset = [create_prompt_and_answer(context) for context in context_samples]\n",
    "\n",
    "# Convert it back to a Hugging Face dataset for consistency\n",
    "pd.DataFrame(processed_dataset).drop(columns=\"context\").to_csv(\"catalanqa.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17628466-c483-4d79-b236-9c090e634f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
